# DiscoveryText

DiscoveryText is an updated version of the extensively popular Coding Analysis Toolkit (CAT), allowing open-ended textual data

## Starting to use DiscoveryText

### Installing the software

DiscoveryText is used through a [web interface](https://discovertext.com/).
We have an educational license within the context of this class, allowing you to trial the software.
Please contact me at grp-dcm-teaching@helsinki.fi to enable the license for you.

### Setting up a project

A project is a collection of documents, each of which is coded.
One must create a project before data can be imported.

### Importing documents.

DiscoveryText allows importing several documents (as text files), or a spreadsheet collection of data.
These collections are known as **Data Archives**, from which you can created **Buckets** and **Data sets** which are subsets of filtered data.
Data sets are needed in the coding stage.

<iframe src="https://player.vimeo.com/video/503173700" width="640" height="313" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>

## Doing data analysis

### Create codes

in DiscoveryText codes must be predefined.
These are known as **code sets**.
A code set is a list of codes, each having a specific analytical **code name**, a **code description** to define what the code means and a short-hand **key** which allows the coder to use the code quickly via the keyboard.
The coder is only able to use the codes defined on a code set.

### Coding data

The coding interface allows the coder to quickly code full coding unit with a given code from the code set.
It is also possible to segment the unit with a specific code, i.e., conduct coding at the level of individual phrases or sentences.
This is done by selecting the segment requiring annotation and then giving the specific text (called trigger text) a code from the code book.

<iframe title="vimeo-player" src="https://player.vimeo.com/video/521409365" width="640" height="356" frameborder="0" allowfullscreen></iframe>

### Analysing reliability

When conducting coding from theory-driven lists, it is important to evaluate how well coders agreed with each others.
There are many ways to evaluate this **inter-rater reliability**, including [Cohen's kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa) and [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha).
DiscoveryText allows you to automatically calculate such evaluations through validating datasets.
